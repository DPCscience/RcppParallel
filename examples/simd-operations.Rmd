---
title: "SIMD Operations"
author: "Kevin Ushey"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SIMD Operations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## SIMD Basics

Modern CPU processors are built with new, extended instruction sets that optimize for certain operations. A class of these allow for vectorized operations, called Single Instruction / Multiple Data (SIMD) instructions. Although modern compilers will use these instructions when possible, it is often not possible for the compiler to reason about whether or not a particular block of code can be executed using SIMD instructions.

`Boost.SIMD` is a C++ header-only library that makes it possible to explicitly request the use of SIMD instructions when possible, while falling back to regular scalar operations if not. `RcppParallel` wraps and exposes this library for use with R vectors.

Here's a quick example of how we might compute the sum of elements in a vector, using `Boost.SIMD`.

```{r, engine='Rcpp'}
// [[Rcpp::depends(RcppParallel)]]
#include <RcppParallel.h>
#include <Rcpp.h>

using namespace RcppParallel;
using namespace Rcpp;

// Define a functor -- a C++ class which defines a 'function call'
// operator -- to perform the addition of two pieces of data.
struct add_two {
   template <typename T>
   T operator()(const T& lhs, const T& rhs) {
      return lhs + rhs;
   }
};

// [[Rcpp::export]]
double simd_sum(NumericVector x) {
   // Use 'simd::accumulate', to sum our vector (by successively adding
   // up pairwise components of the vector)
   return simd::accumulate(x, 0.0, add_two());
}
```

```{r}
data <- rnorm(1024 * 1000)
all.equal(simd_sum(data), sum(data))
if (requireNamespace("microbenchmark", quietly = TRUE)) {
   microbenchmark::microbenchmark(sum(data), simd_sum(data))
}
```


## SIMD Algorithms

Boost.SIMD provides two primary abstractions for the implementation of SIMD algorithms:

- `simd::accumulate()`, for vector -> scalar transformations, and
- `simd::transform()`,  for vector -> vector transformations.

These functions operate like their `std::` counterparts, but expect a functor with a templated call operator. By making the call operator templated, `Boost.SIMD` can generate code using its own optimized SIMD functions when appropriate, and fall back to a default implementation (based on the types provided) when not.

`Boost.SIMD` also provides a number of built in functions, which can be used effectively with `simd::accumulate()` or `simd::transform()`. For example, let's use SIMD instructions to compute the minimum:

```{r, engine='Rcpp'}
// [[Rcpp::depends(RcppParallel)]]
#include <RcppParallel.h>
#include <Rcpp.h>

#include <boost/simd/arithmetic/functions/min.hpp>

using namespace RcppParallel;
using namespace Rcpp;

// [[Rcpp::export]]
NumericVector simd_min(NumericVector data) {
   return simd::transform(data, boost::simd::tag::min_());
}
```

## Using SIMD in an R Package

To build an R package that uses Boost.SIMD you need to make some modifications to the standard RcppParallel configuration:

1. Make sure you call the `CxxFlags` and `LdFlags` functions in `Makevars`
2. Add the **BH** package as a LinkingTo dependency
3. Add C++11 as a SystemRequirement

Here's the complete recipe for using RcppParallel with Boost.SIMD in an R package:

**DESCRIPTION**

```yaml
Imports: RcppParallel
LinkingTo: RcppParallel, BH
SystemRequirements: GNU make, C++11
```

**NAMESPACE**

```R
importFrom(RcppParallel, RcppParallelLibs)
```

**src/Makevars**

```make
PKG_CXXFLAGS += $(shell ${R_HOME}/bin/Rscript -e "RcppParallel::CxxFlags()")
PKG_LIBS += $(shell ${R_HOME}/bin/Rscript -e "RcppParallel::LdFlags()")
```

**src/Makevars.win**

```make
PKG_CXXFLAGS += $(shell "${R_HOME}/bin${R_ARCH_BIN}/Rscript.exe" \ -e "RcppParallel::CxxFlags()")
PKG_LIBS += $(shell "${R_HOME}/bin${R_ARCH_BIN}/Rscript.exe" -e "RcppParallel::LdFlags()")
```

### Platform Compatibility

Note that Boost.SIMD requires a C++11 conformant compiler. This means that packages making use of SIMD features may not compile on platforms with older compilers including Windows and RedHat/CentOS Linux. You can however create a package that takes advantage of Boost.SIMD where available and falls back to a non-SIMD implementation elsewhere.

You can test for the availability of Boost.SIMD on a given platform using the `RCPP_PARALLEL_USE_SIMD` preprocessor variable. If the current compiler doesn't support C++11 (as determined by `__cplusplus <= 199711L`) the variable will be undefined. This allows you to write code like this:

```cpp
#include <RcppParallel.h>

#if RCPP_PARALLEL_USE_SIMD

#include <boost/simd/sdk/simd/pack.hpp>

IntegerVector transformDataImpl(IntegerVector x) {

  // Implement with Boost.SIMD

}

#else

IntegerVector transformDataImpl(IntegerVector x) {

  // Implement without Boost.SIMD

}

#endif

// [[Rcpp::export]]
IntegerVector transformData(IntegerVector x) {
   return transformDataImpl(x);
}

```

The two `transformDataImpl` functions have the same name, but only one will be compiled and linked based on whether the target platform supports Boost.SIMD. 

Note that if you conditionally compile all uses of Boost.SIMD within your package then you can actually drop the `C++11` from `SystemRequirements` (it's no longer required as a result of your fallback implementation).









   





