---
output:
  html_document:
    highlight: textmate
    self_contained: no
    includes: 
      in_header: includes/header.html
      before_body: includes/before.html
      after_body: includes/after.html
---

### Overview

![RcppParallel](images/RcppParallelLogo.png)

High level functions for doing parallel programming with Rcpp. For example, the `parallelFor` function can be used to convert the work of a standard serial "for" loop into a parallel one and the `parallelReduce` function can be used for accumulating aggregate or other values.

The high level interface enables safe and robust parallel programming without direct manipulation of operating system threads. On Windows, OS X, and Linux systems the underlying implementation is based on [Intel TBB](https://www.threadingbuildingblocks.org/) (Threading Building Blocks). On other platforms a less-performant fallback implementation based on the [TinyThread](http://tinythreadpp.bitsnbites.eu/) library is used.

See the examples below for a quick overview of the basic capabilities of the package. Review this guide to learn how to use `parallelFor` and `parallelReduce` in your code (including a discussion of thread safety). For more complex use cases there is also documentation on making direct use of lower-level TBB APIs.

### Examples

Here are links to some examples that illustrate using RcppParallel. Performance benchmarks were executed on a 2.6GHz Haswell MacBook Pro with 4 cores (8 with hyperthreading). 

[Parallel Matrix Transform](http://gallery.rcpp.org/articles/parallel-matrix-transform/) --- Demonstrates using `parallelFor` to transform a matrix (take the square root of each element) in parallel. In this example the parallel version performs about 2.5x faster than the serial version.

[Parallel Vector Sum](http://gallery.rcpp.org/articles/parallel-vector-sum/) --- Demonstrates using `parallelReduce` to take the sum of a vector in parallel. In this example the parallel version performs 4.5x faster than the serial version.

[Parallel Distance Matrix](http://gallery.rcpp.org/articles/parallel-distance-matrix/) --- Demonstrates using `parallelFor` to compute pairwise distances for each row in an input data matrix. In this example the parallel version performs 5.5x faster than the serial version.

[Parallel Inner Product](http://gallery.rcpp.org/articles/parallel-inner-product/) --- Demonstrates using `parallelReduce` to compute the inner product of two vectors in parallel. In this example the parallel version performs 2.5x faster than the serial version.

### Getting Started

You can install the RcppParallel package from CRAN as follows:

```s
install.packages("RcppParallel")
```

#### sourceCpp

Add the following to a standalone C++ source file to import RcppParallel:

```cpp
// [[Rcpp::depends(RcppParallel)]]
#include <RcppParallel.h>
```

When you compile the file using `Rcpp::sourceCpp` the required compiler and linker settings for RcppParallel will be automatically included in the compilation.

#### R Packages

If you want to use RcppParallel from within an R package you add the following to your **DESCRIPTION** file:

```yaml
Imports: RcppParallel
LinkingTo: RcppParallel
```

And the following to your **NAMESPACE** file:

```R
importFrom(RcppParallel, RcppParallelLibs)
```

Finally, for Windows builds you'll need the following in **src\\Makevars.win**
to ensure that your package can use TBB (if you don't do
this the TinyThread fallback implementation will be used):

```make
PKG_CXXFLAGS += -DRCPP_PARALLEL_USE_TBB=1

PKG_LIBS += $(shell "${R_HOME}/bin${R_ARCH_BIN}/Rscript.exe" \
              -e "RcppParallel::RcppParallelLibs()")
```

### Thread Safety

#### R API Restrictions

#### Safe Accessors  

#### Locking

### Algorithms

#### parallelFor

#### parallelReduce

### Using TBB

#### TBB APIs

#### Compatibility

#### Example









