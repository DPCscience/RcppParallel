---
output:
  html_document:
    highlight: textmate
    self_contained: no
    includes: 
      in_header: includes/header.html
      before_body: includes/before.html
      after_body: includes/after.html
---

### Overview

<div id="rcppparallel-header">RcppParallel</div>

High level functions for doing parallel programming with Rcpp. For example, the `parallelFor` function can be used to convert the work of a standard serial "for" loop into a parallel one and the `parallelReduce` function can be used for accumulating aggregate or other values.

The high level interface enables safe and robust parallel programming without direct manipulation of operating system threads. On Windows, OS X, and Linux systems the underlying implementation is based on [Intel TBB](https://www.threadingbuildingblocks.org/) (Threading Building Blocks). On other platforms a less-performant fallback implementation based on the [TinyThread](http://tinythreadpp.bitsnbites.eu/) library is used.

### Examples

Here are links to some examples that illustrate using RcppParallel. Performance benchmarks were executed on a 2.6GHz Haswell MacBook Pro with 4 cores (8 with hyperthreading). 

[Parallel Matrix Transform](http://gallery.rcpp.org/articles/parallel-matrix-transform/) --- Demonstrates using `parallelFor` to transform a matrix (take the square root of each element) in parallel. In this example the parallel version performs about 2.5x faster than the serial version.

[Parallel Vector Sum](http://gallery.rcpp.org/articles/parallel-vector-sum/) --- Demonstrates using `parallelReduce` to take the sum of a vector in parallel. In this example the parallel version performs 4.5x faster than the serial version.

[Parallel Distance Matrix](http://gallery.rcpp.org/articles/parallel-distance-matrix/) --- Demonstrates using `parallelFor` to compute pairwise distances for each row in an input data matrix. In this example the parallel version performs 5.5x faster than the serial version.

[Parallel Inner Product](http://gallery.rcpp.org/articles/parallel-inner-product/) --- Demonstrates using `parallelReduce` to compute the inner product of two vectors in parallel. In this example the parallel version performs 2.5x faster than the serial version.

### Usage

You can install the RcppParallel package from CRAN as follows:

```s
install.packages("RcppParallel")
```

#### sourceCpp

You can use the RcppParallel library from within a standalone C++ source file as follows:

```cpp
// [[Rcpp::depends(RcppParallel)]]
#include <RcppParallel.h>
```

#### Packages

If you want to use RcppParallel from within an R package you add the following to your **DESCRIPTION** file:

```yaml
Imports: RcppParallel
LinkingTo: RcppParallel
```

And the following to your **NAMESPACE** file:

```R
importFrom(RcppParallel, RcppParallelLibs)
```

Finally, for Windows builds you'll need the following in **src\\Makevars.win**
to ensure that your package can use TBB (if you don't do
this the TinyThread fallback implementation will be used):

```make
PKG_CXXFLAGS += -DRCPP_PARALLEL_USE_TBB=1

PKG_LIBS += $(shell "${R_HOME}/bin${R_ARCH_BIN}/Rscript.exe" \
              -e "RcppParallel::RcppParallelLibs()")
```

