<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<title></title>

<script src="index_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.1/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.1/shim/respond.min.js"></script>

<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet">

<script src="libs/tocify-1.9.1/jquery-ui-1.9.2.custom.min.js"></script>
<script src="libs/tocify-1.9.1/jquery.tocify.min.js"></script>

<style type="text/css">
@media (max-width: 992px) {
#toc {
  position: relative;
  width: 100%;
  margin: 0px 0px 20px 0px;
}
}
</style>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="index_files/highlight/textmate.css"
      type="text/css" />
<script src="index_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div class="row-fluid">

<div class="span3 col-md-3">
  <div id="toc"></div>
</div>

<div class="main-content span9 col-md-9">

<style type="text/css">
body {
  padding-top: 20px;
}
/* offset scroll position for anchor links */
h3 {
  padding-top: 25px;
  margin-top: -25px;
}
h4 {
  padding-top: 25px;
  margin-top: -25px;
}
.section {
  margin-bottom: 25px;
}

.tocify {
  border: none;
  background-color: #ECF2F6;
}

.tocify .list-group-item {
  border-radius: 0px;
  background-color: #ECF2F6;
  padding-top: 0px;
  padding-bottom: 0px;
  color: #337ab7;
}

.tocify .list-group-item.active {
  color: white;
  background-color: #428DC8;
}

.tocify .list-group-item:hover {
  background-color: #caddec;
}

.tocify .list-group-item.active:hover {
  color: white;
  background-color: #428DC8;
}

.tocify-subheader {
  display: inline;
}

.tocify-subheader .tocify-item {
  font-size: 0.95em;
  padding-left: 12px;
}

#overview h3 {
  visibility: hidden;
  height: 0px;
}

blockquote {
  font-size: 1em;
}

</style>



<div id="overview" class="section level3">
<h3>Overview</h3>
<p><img src="images/RcppParallelLogo.png" alt="RcppParallel" /></p>
<p>High level functions for doing parallel programming with Rcpp. For example, the <code>parallelFor</code> function can be used to convert the work of a standard serial “for” loop into a parallel one and the <code>parallelReduce</code> function can be used for accumulating aggregate or other values.</p>
<p>The high level interface enables safe and robust parallel programming without direct manipulation of operating system threads. On Windows, OS X, and Linux systems the underlying implementation is based on <a href="https://www.threadingbuildingblocks.org/">Intel TBB</a> (Threading Building Blocks). On other platforms a less-performant fallback implementation based on the <a href="http://tinythreadpp.bitsnbites.eu/">TinyThread</a> library is used.</p>
<p>In addition to a robust concurrent programming model, parallization using TBB can achieve significantly better performance than traditional use of threads or even <a href="http://openmp.org/wp/">OpenMP</a>. This is accomplished via dynamic optimization around grain size (which affects locality of reference and therefore cache hit rates) as well as work stealing (detecting idle threads and pushing work to them).</p>
<p>This guide describes how to use <code>parallelFor</code> and <code>parallelReduce</code> in your code (including a discussion of thread safety). For more complex use cases there is also documentation on making direct use of lower-level TBB APIs.</p>
</div>
<div id="getting-started" class="section level3">
<h3>Getting Started</h3>
<p>You can install the RcppParallel package from CRAN as follows:</p>
<pre class="s"><code>install.packages(&quot;RcppParallel&quot;)</code></pre>
<div id="sourcecpp" class="section level4">
<h4>sourceCpp</h4>
<p>Add the following to a standalone C++ source file to import RcppParallel:</p>
<pre class="cpp"><code>// [[Rcpp::depends(RcppParallel)]]
#include &lt;RcppParallel.h&gt;</code></pre>
<p>When you compile the file using <code>Rcpp::sourceCpp</code> the required compiler and linker settings for RcppParallel will be automatically included in the compilation.</p>
</div>
<div id="r-packages" class="section level4">
<h4>R Packages</h4>
<p>If you want to use RcppParallel from within an R package you add the following to your <strong>DESCRIPTION</strong> file:</p>
<pre class="yaml"><code>Imports: RcppParallel
LinkingTo: RcppParallel</code></pre>
<p>And the following to your <strong>NAMESPACE</strong> file:</p>
<pre class="r"><code>importFrom(RcppParallel, RcppParallelLibs)</code></pre>
<p>Finally, for Windows builds you’ll need the following in <strong>src\Makevars.win</strong> to ensure that your package can use TBB (if you don’t do this the TinyThread fallback implementation will be used):</p>
<pre class="make"><code>PKG_CXXFLAGS += -DRCPP_PARALLEL_USE_TBB=1

PKG_LIBS += $(shell &quot;${R_HOME}/bin${R_ARCH_BIN}/Rscript.exe&quot; \
              -e &quot;RcppParallel::RcppParallelLibs()&quot;)</code></pre>
<p>Then in each source file that needs to use RcppParallel include the main package header:</p>
<pre class="cpp"><code>#include &lt;RcppParallel.h&gt;</code></pre>
</div>
</div>
<div id="thread-safety" class="section level3">
<h3>Thread Safety</h3>
<p>A major goal of RcppParallel is to make it possible to write parallel code without traditional threading and locking primitives (which are notoriously complicated and difficult to get right). This is achieved for the most part by <code>parallelFor</code> and <code>parallelReduce</code> however the fact that the R API itself is single-threaded must also be navigated.</p>
<div id="api-restrictions" class="section level4">
<h4>API Restrictions</h4>
<p>The code that you write within parallel workers should not call the R or Rcpp API in any fashion. This is because R itself is single-threaded and concurrent interaction with it’s data structures will cause crashes and other undefined behavior. Here is the official guidance from <a href="http://cran.rstudio.com/doc/manuals/r-release/R-exts.html">Writing R Extensions</a>:</p>
<blockquote>
<p>Calling any of the R API from threaded code is ‘for experts only’: they will need to read the source code to determine if it is thread-safe. In particular, code which makes use of the stack-checking mechanism must not be called from threaded code.</p>
</blockquote>
<p>Not being able to call the R or Rcpp API creates an obvious challenge: how to read and write to R vectors and matrixes. Fortunately, R vectors and matrixes are just contiguous arrays of <code>int</code>, <code>double</code>, etc. so can be accessed using traditional array and pointer offsets. The next section describes a safe and high level way to do this.</p>
</div>
<div id="safe-accessors" class="section level4">
<h4>Safe Accessors</h4>
<p>To provide safe and convinent access to the arrays underlying R vectors and matrixes RcppParallel introduces several accessor classes:</p>
<ul>
<li><p><code>RVector&lt;T&gt;</code> — Wrap R vectors of various types</p></li>
<li><p><code>RMatrix&lt;T&gt;</code> — Wrap R matrixes of various types (also includes <code>Row</code> and <code>Column</code> classes)</p></li>
</ul>
<p>To create a threadsafe accessor for an Rcpp vector or matrix just construct an instance of <code>RVector</code> or <code>RMatrix</code> with it. For example:</p>
<pre class="cpp"><code>// [[Rcpp::export]]
IntegerVector transformVector(IntegerVector x) {
  RVector&lt;int&gt; input(x);
  // etc...
}</code></pre>
<p>Similarly, if you need to return a vector as a result of a parallel transformation you should first create it using Rcpp then construct a wrapper for writing from multiple threads. For example:</p>
<pre class="cpp"><code>// [[Rcpp::export]]
IntegerVector transformVector(IntegerVector x) {
  RVector&lt;int&gt; input(x);        // create threadsafe wrapper to input
  IntegerVector y(x.size());    // allocate output vector
  RVector&lt;int&gt; output(y);       // create threadsafe wrapper to output
  
  // ...transform vector in parallel ...
  
  return y;
}</code></pre>
</div>
<div id="locking" class="section level4">
<h4>Locking</h4>
<p>When using RcppParallel you typically do not need to worry about explicit locking, as the mechanics of <code>parallelFor</code> and <code>parallelReduce</code> (explained below) take care of providing safe windows into input and ouptut data that have no possibility of contention. Nevertheless, if for some reason you do need to synchronize access to shared data, you an use the TinyThread locking classes (automatically available via <code>RcppParallel.h</code>). See the <a href="http://tinythreadpp.bitsnbites.eu/doc/">TinyThread documentation</a> for additional details.</p>
</div>
</div>
<div id="algorithms" class="section level3">
<h3>Algorithms</h3>
<p>RcppParallel provides two high level parallel algorithms: <code>parallelFor</code> can be used to convert the work of a standard serial “for” loop into a parallel one and <code>parallelReduce</code> can be used for accumulating aggregate or other values.</p>
<div id="parallelfor" class="section level4">
<h4>parallelFor</h4>
<p>To use <code>parallelFor</code>, you create a “Worker” object that defines an <code>operator()</code> which is called by the parallel scheduler. This function is passed begin/end ranges which are safe windows (i.e. not in use by other threads) into the input or output data. For example, here’s a Worker object that takes the square root of it’s input and writes it into it’s output:</p>
<pre class="cpp"><code>// [[Rcpp::depends(RcppParallel)]]
#include &lt;RcppParallel.h&gt;
using namespace RcppParallel;

struct SquareRoot : public Worker
{
   // source matrix
   const RMatrix&lt;double&gt; input;
   
   // destination matrix
   RMatrix&lt;double&gt; output;
   
   // initialize with source and destination
   SquareRoot(const NumericMatrix input, NumericMatrix output) 
      : input(input), output(output) {}
   
   // take the square root of the range of elements requested
   void operator()(std::size_t begin, std::size_t end) {
      std::transform(input.begin() + begin, 
                     input.begin() + end, 
                     output.begin() + begin, 
                     ::sqrt);
   }
};
</code></pre>
<p>Note that <code>SquareRoot</code> derives from <code>RcppParallel::Worker</code>. This is required for function objects passed to <code>parallelFor</code>.</p>
<p>Here’s a function that calls the <code>SquareRoot</code> worker we defined:</p>
<pre class="cpp"><code>// [[Rcpp::export]]
NumericMatrix parallelMatrixSqrt(NumericMatrix x) {
  
  // allocate the output matrix
  NumericMatrix output(x.nrow(), x.ncol());
  
  // SquareRoot functor (pass input and output matrixes)
  SquareRoot squareRoot(x, output);
  
  // call parallelFor to do the work
  parallelFor(0, x.length(), squareRoot);
  
  // return the output matrix
  return output;
}</code></pre>
</div>
<div id="parallelreduce" class="section level4">
<h4>parallelReduce</h4>
<p>To use <code>parallelReduce</code> you create a “Worker” object that:</p>
<ol style="list-style-type: decimal">
<li><p>Implements a standard and “splitting” constructor. The standard constructor takes the input data and initializes whatever value is being accumulated (e.g. initialize a sum to zero). The splitting constructor is called when work needs to be split onto other threads—it takes a reference to the instance it is being split from and simply copies the pointer to the input data and initializes it’s “accumulated” value back to it’s baseline (e.g. zero).</p></li>
<li><p>Implements operator() to perform the work. This works just like the operator() in parallelFor, but instead of writing to another vector or matrix it typically will accumulate a value.</p></li>
<li><p>Implements a join method which composes the operations of two worker instances that were previously split. Here we simply combine the accumulated value of the instance we are being joined with to our own.</p></li>
</ol>
<p>For example, here’s a Worker object that is used to sum a vector:</p>
<pre class="cpp"><code>// [[Rcpp::depends(RcppParallel)]]
#include &lt;RcppParallel.h&gt;
using namespace RcppParallel;

struct Sum : public Worker
{   
   // source vector
   const RVector&lt;double&gt; input;
   
   // accumulated value
   double value;
   
   // constructors
   Sum(const NumericVector input) : input(input), value(0) {}
   Sum(const Sum&amp; sum, Split) : input(sum.input), value(0) {}
   
   // accumulate just the element of the range I&#39;ve been asked to
   void operator()(std::size_t begin, std::size_t end) {
      value += std::accumulate(input.begin() + begin, input.begin() + end, 0.0);
   }
     
   // join my value with that of another Sum
   void join(const Sum&amp; rhs) { 
      value += rhs.value; 
   }
};</code></pre>
<p>Now that we’ve defined the Worker, implementing the parallel sum function is straightforward. Just initialize an instance of <code>Sum</code> with an input vector and call <code>parallelReduce</code>:</p>
<pre class="cpp"><code>// [[Rcpp::export]]
double parallelVectorSum(NumericVector x) {
   
   // declare the SumBody instance 
   Sum sum(x);
   
   // call parallel_reduce to start the work
   parallelReduce(0, x.length(), sum);
   
   // return the computed sum
   return sum.value;
}</code></pre>
</div>
<div id="examples" class="section level4">
<h4>Examples</h4>
<p>Here are links to some examples that illustrate using <code>parallelFor</code> and <code>parallelReduce</code> Performance benchmarks were executed on a 2.6GHz Haswell MacBook Pro with 4 cores (8 with hyperthreading).</p>
<p><a href="http://gallery.rcpp.org/articles/parallel-matrix-transform/">Parallel Matrix Transform</a> — Demonstrates using <code>parallelFor</code> to transform a matrix (take the square root of each element) in parallel. In this example the parallel version performs about 2.5x faster than the serial version.</p>
<p><a href="http://gallery.rcpp.org/articles/parallel-vector-sum/">Parallel Vector Sum</a> — Demonstrates using <code>parallelReduce</code> to take the sum of a vector in parallel. In this example the parallel version performs 4.5x faster than the serial version.</p>
<p><a href="http://gallery.rcpp.org/articles/parallel-distance-matrix/">Parallel Distance Matrix</a> — Demonstrates using <code>parallelFor</code> to compute pairwise distances for each row in an input data matrix. In this example the parallel version performs 5.5x faster than the serial version.</p>
<p><a href="http://gallery.rcpp.org/articles/parallel-inner-product/">Parallel Inner Product</a> — Demonstrates using <code>parallelReduce</code> to compute the inner product of two vectors in parallel. In this example the parallel version performs 2.5x faster than the serial version.</p>
</div>
</div>
<div id="tuning" class="section level3">
<h3>Tuning</h3>
<div id="grain-size" class="section level4">
<h4>Grain Size</h4>
</div>
<div id="threads-used" class="section level4">
<h4>Threads Used</h4>
</div>
<div id="benchmarking" class="section level4">
<h4>Benchmarking</h4>
</div>
</div>
<div id="using-tbb" class="section level3">
<h3>Using TBB</h3>
<div id="tbb-apis" class="section level4">
<h4>TBB APIs</h4>
</div>
<div id="compatibility" class="section level4">
<h4>Compatibility</h4>
</div>
<div id="examples-1" class="section level4">
<h4>Examples</h4>
</div>
</div>


</div> <!--span-9-->
</div> <!--row-fluid-->

<style type="text/css">
.main-container {
  max-width: none;
}
</style>

<script>
$(function() {
    var toc = $("#toc").tocify({
      selectors: "h3,h4",
      theme: "bootstrap3",
      context: '.main-content',
      hashGenerator: 'pretty',
      showAndHide: false
    }).data("toc-tocify");
    $(".optionName").popover({ trigger: "hover" });
});
</script>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
